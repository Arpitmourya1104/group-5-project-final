name: Run PySpark Script

on:
  push:
    branches:
      - main

jobs:
  pyspark-job:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Java JDK
      uses: actions/setup-java@v3
      with:
        java-version: '11'

    - name: Install Spark
      run: |
        wget http://www.apache.org/dyn/closer.cgi/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz
        tar xvf spark-3.3.2-bin-hadoop3.tgz
        echo "SPARK_HOME=$(pwd)/spark-3.3.2-bin-hadoop3" >> $GITHUB_ENV
        echo "$SPARK_HOME/bin" >> $GITHUB_PATH

    - name: Install PySpark
      run: |
        pip install pyspark

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: Run PySpark Script
      run: |
        spark-submit s3_transfer.py
