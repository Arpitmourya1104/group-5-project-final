name: S3 CSV to Parquet Transfer

on:
  push:
    branches:
      - main

jobs:
  s3-transfer:
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 pyspark

      - name: Download Hadoop AWS and AWS SDK JARs
        run: |
          mkdir -p jars
          curl -L -o jars/hadoop-aws-3.3.1.jar https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.1/hadoop-aws-3.3.1.jar
          curl -L -o jars/aws-java-sdk-bundle-1.11.888.jar https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.888/aws-java-sdk-bundle-1.11.888.jar

      - name: Run S3 transfer script
        run: |
          spark-submit --jars jars/hadoop-aws-3.3.1.jar,jars/aws-java-sdk-bundle-1.11.888.jar s3_transfer.py
